{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"mUC2fqosGAAP"},"source":[" *Artificial Intelligence for Vision & NLP* &nbsp; | &nbsp;  *ATU Donegal - MSc/PGDip in Big Data Analytics & Artificial Intelligence*\n"," \n"," # Lemmatisation\n","\n","In contrast to stemming, lemmatisation looks beyond word reduction, and considers a language's full vocabulary to apply a *morphological analysis* to words. This is the grammatical analysis of the formation of words from morphemes.\n","\n","For example, the lemma of *was* is *be* and the lemma of *mice* is *mouse*. The lemma of *meeting* might be *meet** or *meeting* depending on its use in a sentence."]},{"cell_type":"markdown","metadata":{"id":"TXPiQQVWGAAZ"},"source":["Firstly we import the `spaCy` library and the language model. Then we load the relevant language model. In this example, I'm using the **English language** model. The model will be stored in the instance called `nlp`."]},{"cell_type":"code","metadata":{"id":"EXmJ9EJeGAAg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394758218,"user_tz":0,"elapsed":12509,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"d0985e79-a57c-468b-fcde-a362682def2e"},"source":["import spacy\n","nlp = spacy.load('en_core_web_sm')\n","\n","# Alternatively we could load the English language library as follows\n","# from spacy.lang.en import English\n","# nlp = English()"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n"]}]},{"cell_type":"markdown","metadata":{"id":"L-dQdya-GAAh"},"source":["Next we create a short sentence and assign it to a `spaCy` document object."]},{"cell_type":"code","metadata":{"id":"Ld2WquV4GAAh","executionInfo":{"status":"ok","timestamp":1679394758218,"user_tz":0,"elapsed":10,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}}},"source":["doc_object = nlp(u\"I ate an apple before I went to class. I'm still feeling hungry though.\")"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QW3fSNhjGAAi"},"source":["Let's see what tokens we have in the document, as well as the associated *parts-of-speech (POS)* tags using the `.pos_` attribute:"]},{"cell_type":"code","metadata":{"id":"GvJmy-AQGAAi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394758219,"user_tz":0,"elapsed":10,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"07c0a7e2-6a2c-4a43-a5c9-592b1e07f78b"},"source":["for token in doc_object:\n","    print(token, token.pos_)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["I PRON\n","ate VERB\n","an DET\n","apple NOUN\n","before SCONJ\n","I PRON\n","went VERB\n","to ADP\n","class NOUN\n",". PUNCT\n","I PRON\n","'m AUX\n","still ADV\n","feeling VERB\n","hungry ADJ\n","though ADV\n",". PUNCT\n"]}]},{"cell_type":"markdown","metadata":{"id":"k2oeit82GAAj"},"source":["Now I'd like to examine all of the root words from my sentence. "]},{"cell_type":"code","metadata":{"id":"moMoRWVkGAAj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394758219,"user_tz":0,"elapsed":8,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"39d767fe-c15f-42f8-d812-fa8804033ca6"},"source":["for word in doc_object:\n","    print(word.text + \" -----> \" + word.lemma_)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["I -----> I\n","ate -----> eat\n","an -----> an\n","apple -----> apple\n","before -----> before\n","I -----> I\n","went -----> go\n","to -----> to\n","class -----> class\n",". -----> .\n","I -----> I\n","'m -----> be\n","still -----> still\n","feeling -----> feel\n","hungry -----> hungry\n","though -----> though\n",". -----> .\n"]}]},{"cell_type":"markdown","metadata":{"id":"A8GQPY_yGAAk"},"source":["Lets see what happens with the words we used in the stemming example, and compare the root words identified by lemmatisation versus stemming."]},{"cell_type":"code","metadata":{"id":"4mMLBK7kGAAk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394758219,"user_tz":0,"elapsed":6,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"51fb96b0-2982-465c-f2bf-6e8a20b1bacd"},"source":["sample_words = nlp(u\"caresses ponies pony cats running runner climber easily quickly\")\n","\n","for word in sample_words:\n","    print(word.text + \" -----> \" + word.lemma_, \"\\t\", word.pos_)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["caresses -----> caress \t VERB\n","ponies -----> pony \t NOUN\n","pony -----> pony \t ADJ\n","cats -----> cat \t NOUN\n","running -----> run \t VERB\n","runner -----> runner \t NOUN\n","climber -----> climber \t NOUN\n","easily -----> easily \t ADV\n","quickly -----> quickly \t ADV\n"]}]},{"cell_type":"markdown","metadata":{"id":"GQdSMAJGGAAl"},"source":["The stemming output was as follows:\n","\n","```\n","caresses ------> caress\n","ponies ------> poni\n","pony ------> poni\n","cats ------> cat\n","running ------> run\n","runner ------> runner\n","climber ------> climber\n","easily ------> easili\n","quickly ------> quickli\n","```\n","\n","We can see that unlike stemming where the root we got was *poni* for *ponies*, the roots that we arrived at through lemmatisation are actual words in the English dictionary.\n","\n","Lemmatisation converts words in the second or third forms to their first form variants."]},{"cell_type":"markdown","metadata":{"id":"S4clY2DKGAAl"},"source":["Next we create a simple function to input some NLP text and then use f-string formatting to tidy the output."]},{"cell_type":"code","metadata":{"id":"pH_TrW_uGAAm","executionInfo":{"status":"ok","timestamp":1679394758219,"user_tz":0,"elapsed":5,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}}},"source":["def create_lemmatization(text_to_convert):\n","    for token in text_to_convert:\n","        print (f\"{token.text:{15}} {token.lemma_:{30}}\")"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zBWW0ttvGAAm"},"source":["Let's use this on an NLP sentence:"]},{"cell_type":"code","metadata":{"id":"OanT0DIRGAAm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394758219,"user_tz":0,"elapsed":5,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"431fac19-da41-40d8-d433-01cf8bd75d3c"},"source":["doc_object = nlp(u\"The brown fox is quick and he is jumping over the lazy dog\")\n","# Call the lemmatization function with my sentence\n","create_lemmatization(doc_object)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["The             the                           \n","brown           brown                         \n","fox             fox                           \n","is              be                            \n","quick           quick                         \n","and             and                           \n","he              he                            \n","is              be                            \n","jumping         jump                          \n","over            over                          \n","the             the                           \n","lazy            lazy                          \n","dog             dog                           \n"]}]},{"cell_type":"markdown","metadata":{"id":"25ls90ntGAAn"},"source":["Note that the lemmatisation of *is* is *be* - the name of the verb."]},{"cell_type":"markdown","metadata":{"id":"Wc99fqrWGAAn"},"source":["# More Part-of-Speech Tagging\n","\n","Processing raw text intelligently is difficult. Lots of words that look completely different can mean almost the same thing. The same words in a different order can mean something completely different. Even splitting text into useful word-like units can be difficult in many languages. While it's possible to solve some problems starting from only the raw characters, it's usually better to use linguistic knowledge to add useful information. That's exactly what `spaCy` is designed to do: you put in raw text, and get back a `Doc` object, that comes with a variety of annotations.\n","\n","As we've seen previously, a *Part-Of-Speech Tagger (POS Tagger)* reads text in some language and assigns parts of speech to each word (and other token), such as noun, verb, adjective, etc., although generally computational applications use more fine-grained POS tags like 'noun-plural'.\n","\n","In this section we'll look at POS tags in more detail."]},{"cell_type":"markdown","metadata":{"id":"OhRHgXvRGAAn"},"source":["### View Token Tags\n","We can obtain a particular token by its index position.\n","* To view the coarse POS tag use `token.pos_`\n","* To view the fine-grained tag use `token.tag_`\n","* To view the description of either type of tag use `spacy.explain(tag)`\n","\n","Note that `token.pos` and `token.tag` commands return integer hash values. By adding the underscores we get the text (string) equivalent that lives in `doc.vocab`. So the data returned by adding the underscore is more meaningful to us than just the integer hash value."]},{"cell_type":"markdown","metadata":{"id":"VYn5aT0gGAAo"},"source":["Before we begin, lets have a look at the full ine of text that we'll now work on."]},{"cell_type":"code","metadata":{"id":"aOpN4xbyGAAo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394758717,"user_tz":0,"elapsed":502,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"9b84a5f1-8046-411a-bf57-7506492c5136"},"source":["doc_object = nlp(u\"I ate an apple before I went to class. I'm still feeling hungry though.\")\n","print(doc_object)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["I ate an apple before I went to class. I'm still feeling hungry though.\n"]}]},{"cell_type":"markdown","metadata":{"id":"fPP9VlWnGAAo"},"source":["The `doc` object contains information on the *predictive POS tag* as well as other interexting attributes. We can easily show the POS tags generated by `spaCy` through a loop."]},{"cell_type":"code","metadata":{"id":"pS3t6WFzGAAp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394758718,"user_tz":0,"elapsed":22,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"7de9dd82-5292-48e0-997f-d025708a4e50"},"source":["for token in doc_object:\n","        print(f\" {token.text:{20}} {token.pos_:{10}} {token.tag_:{5}} {spacy.explain(token.tag_)}\")"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":[" I                    PRON       PRP   pronoun, personal\n"," ate                  VERB       VBD   verb, past tense\n"," an                   DET        DT    determiner\n"," apple                NOUN       NN    noun, singular or mass\n"," before               SCONJ      IN    conjunction, subordinating or preposition\n"," I                    PRON       PRP   pronoun, personal\n"," went                 VERB       VBD   verb, past tense\n"," to                   ADP        IN    conjunction, subordinating or preposition\n"," class                NOUN       NN    noun, singular or mass\n"," .                    PUNCT      .     punctuation mark, sentence closer\n"," I                    PRON       PRP   pronoun, personal\n"," 'm                   AUX        VBP   verb, non-3rd person singular present\n"," still                ADV        RB    adverb\n"," feeling              VERB       VBG   verb, gerund or present participle\n"," hungry               ADJ        JJ    adjective (English), other noun-modifier (Chinese)\n"," though               ADV        RB    adverb\n"," .                    PUNCT      .     punctuation mark, sentence closer\n"]}]},{"cell_type":"markdown","metadata":{"id":"K7R291nqGAAp"},"source":["The `pos_` tag represents the *part-of-speech* tag for each word. For example lets examine the word *went*.\n","\n","We can see that the POS tag (the course-grained POS tag) for *went* is VERB, and this is correct since *went* is a verb.\n","\n","The *fine-grained POS tag* for the word *went* is VBD. We can use the command `spacy.explain()` to show more information on what the VBD tag means. \n","\n","The full explanation of VBD* is *verb, past tense*."]},{"cell_type":"markdown","metadata":{"id":"_EQWt2uaGAAp"},"source":["Every token is assigned a course-grained POS Tag from the following list:\n","\n","\n","<table><tr><th>POS</th><th>DESCRIPTION</th><th>EXAMPLES</th></tr>\n","    \n","<tr><td>ADJ</td><td>adjective</td><td>*big, old, green, incomprehensible, first*</td></tr>\n","<tr><td>ADP</td><td>adposition</td><td>*in, to, during*</td></tr>\n","<tr><td>ADV</td><td>adverb</td><td>*very, tomorrow, down, where, there*</td></tr>\n","<tr><td>AUX</td><td>auxiliary</td><td>*is, has (done), will (do), should (do)*</td></tr>\n","<tr><td>CONJ</td><td>conjunction</td><td>*and, or, but*</td></tr>\n","<tr><td>CCONJ</td><td>coordinating conjunction</td><td>*and, or, but*</td></tr>\n","<tr><td>DET</td><td>determiner</td><td>*a, an, the*</td></tr>\n","<tr><td>INTJ</td><td>interjection</td><td>*psst, ouch, bravo, hello*</td></tr>\n","<tr><td>NOUN</td><td>noun</td><td>*girl, cat, tree, air, beauty*</td></tr>\n","<tr><td>NUM</td><td>numeral</td><td>*1, 2017, one, seventy-seven, IV, MMXIV*</td></tr>\n","<tr><td>PART</td><td>particle</td><td>*'s, not,*</td></tr>\n","<tr><td>PRON</td><td>pronoun</td><td>*I, you, he, she, myself, themselves, somebody*</td></tr>\n","<tr><td>PROPN</td><td>proper noun</td><td>*Mary, John, London, NATO, HBO*</td></tr>\n","<tr><td>PUNCT</td><td>punctuation</td><td>*., (, ), ?*</td></tr>\n","<tr><td>SCONJ</td><td>subordinating conjunction</td><td>*if, while, that*</td></tr>\n","<tr><td>SYM</td><td>symbol</td><td>*$, %, §, ©, +, −, ×, ÷, =, :), 😝*</td></tr>\n","<tr><td>VERB</td><td>verb</td><td>*run, runs, running, eat, ate, eating*</td></tr>\n","<tr><td>X</td><td>other</td><td>*sfpksdpsxmsa*</td></tr>\n","<tr><td>SPACE</td><td>space</td></tr>"]},{"cell_type":"markdown","metadata":{"id":"X3w52VDbGAAr"},"source":["\n","Tokens are subsequently given a fine-grained tag as determined by morphology:\n","<table>\n","<tr><th>POS</th><th>Description</th><th>Fine-grained Tag</th><th>Description</th><th>Morphology</th></tr>\n","<tr><td>ADJ</td><td>adjective</td><td>AFX</td><td>affix</td><td>Hyph=yes</td></tr>\n","<tr><td>ADJ</td><td></td><td>JJ</td><td>adjective</td><td>Degree=pos</td></tr>\n","<tr><td>ADJ</td><td></td><td>JJR</td><td>adjective, comparative</td><td>Degree=comp</td></tr>\n","<tr><td>ADJ</td><td></td><td>JJS</td><td>adjective, superlative</td><td>Degree=sup</td></tr>\n","<tr><td>ADJ</td><td></td><td>PDT</td><td>predeterminer</td><td>AdjType=pdt PronType=prn</td></tr>\n","<tr><td>ADJ</td><td></td><td>PRP\\$</td><td>pronoun, possessive</td><td>PronType=prs Poss=yes</td></tr>\n","<tr><td>ADJ</td><td></td><td>WDT</td><td>wh-determiner</td><td>PronType=int rel</td></tr>\n","<tr><td>ADJ</td><td></td><td>WP\\$</td><td>wh-pronoun, possessive</td><td>Poss=yes PronType=int rel</td></tr>\n","<tr><td>ADP</td><td>adposition</td><td>IN</td><td>conjunction, subordinating or preposition</td><td></td></tr>\n","<tr><td>ADV</td><td>adverb</td><td>EX</td><td>existential there</td><td>AdvType=ex</td></tr>\n","<tr><td>ADV</td><td></td><td>RB</td><td>adverb</td><td>Degree=pos</td></tr>\n","<tr><td>ADV</td><td></td><td>RBR</td><td>adverb, comparative</td><td>Degree=comp</td></tr>\n","<tr><td>ADV</td><td></td><td>RBS</td><td>adverb, superlative</td><td>Degree=sup</td></tr>\n","<tr><td>ADV</td><td></td><td>WRB</td><td>wh-adverb</td><td>PronType=int rel</td></tr>\n","<tr><td>CONJ</td><td>conjunction</td><td>CC</td><td>conjunction, coordinating</td><td>ConjType=coor</td></tr>\n","<tr><td>DET</td><td>determiner</td><td>DT</td><td>determiner</td><td></td></tr>\n","<tr><td>INTJ</td><td>interjection</td><td>UH</td><td>interjection</td><td></td></tr>\n","<tr><td>NOUN</td><td>noun</td><td>NN</td><td>noun, singular or mass</td><td>Number=sing</td></tr>\n","<tr><td>NOUN</td><td></td><td>NNS</td><td>noun, plural</td><td>Number=plur</td></tr>\n","<tr><td>NOUN</td><td></td><td>WP</td><td>wh-pronoun, personal</td><td>PronType=int rel</td></tr>\n","<tr><td>NUM</td><td>numeral</td><td>CD</td><td>cardinal number</td><td>NumType=card</td></tr>\n","<tr><td>PART</td><td>particle</td><td>POS</td><td>possessive ending</td><td>Poss=yes</td></tr>\n","<tr><td>PART</td><td></td><td>RP</td><td>adverb, particle</td><td></td></tr>\n","<tr><td>PART</td><td></td><td>TO</td><td>infinitival to</td><td>PartType=inf VerbForm=inf</td></tr>\n","<tr><td>PRON</td><td>pronoun</td><td>PRP</td><td>pronoun, personal</td><td>PronType=prs</td></tr>\n","<tr><td>PROPN</td><td>proper noun</td><td>NNP</td><td>noun, proper singular</td><td>NounType=prop Number=sign</td></tr>\n","<tr><td>PROPN</td><td></td><td>NNPS</td><td>noun, proper plural</td><td>NounType=prop Number=plur</td></tr>\n","<tr><td>PUNCT</td><td>punctuation</td><td>-LRB-</td><td>left round bracket</td><td>PunctType=brck PunctSide=ini</td></tr>\n","<tr><td>PUNCT</td><td></td><td>-RRB-</td><td>right round bracket</td><td>PunctType=brck PunctSide=fin</td></tr>\n","<tr><td>PUNCT</td><td></td><td>,</td><td>punctuation mark, comma</td><td>PunctType=comm</td></tr>\n","<tr><td>PUNCT</td><td></td><td>:</td><td>punctuation mark, colon or ellipsis</td><td></td></tr>\n","<tr><td>PUNCT</td><td></td><td>.</td><td>punctuation mark, sentence closer</td><td>PunctType=peri</td></tr>\n","<tr><td>PUNCT</td><td></td><td>''</td><td>closing quotation mark</td><td>PunctType=quot PunctSide=fin</td></tr>\n","<tr><td>PUNCT</td><td></td><td>\"\"</td><td>closing quotation mark</td><td>PunctType=quot PunctSide=fin</td></tr>\n","<tr><td>PUNCT</td><td></td><td>``</td><td>opening quotation mark</td><td>PunctType=quot PunctSide=ini</td></tr>\n","<tr><td>PUNCT</td><td></td><td>HYPH</td><td>punctuation mark, hyphen</td><td>PunctType=dash</td></tr>\n","<tr><td>PUNCT</td><td></td><td>LS</td><td>list item marker</td><td>NumType=ord</td></tr>\n","<tr><td>PUNCT</td><td></td><td>NFP</td><td>superfluous punctuation</td><td></td></tr>\n","<tr><td>SYM</td><td>symbol</td><td>#</td><td>symbol, number sign</td><td>SymType=numbersign</td></tr>\n","<tr><td>SYM</td><td></td><td>\\$</td><td>symbol, currency</td><td>SymType=currency</td></tr>\n","<tr><td>SYM</td><td></td><td>SYM</td><td>symbol</td><td></td></tr>\n","<tr><td>VERB</td><td>verb</td><td>BES</td><td>auxiliary \"be\"</td><td></td></tr>\n","<tr><td>VERB</td><td></td><td>HVS</td><td>forms of \"have\"</td><td></td></tr>\n","<tr><td>VERB</td><td></td><td>MD</td><td>verb, modal auxiliary</td><td>VerbType=mod</td></tr>\n","<tr><td>VERB</td><td></td><td>VB</td><td>verb, base form</td><td>VerbForm=inf</td></tr>\n","<tr><td>VERB</td><td></td><td>VBD</td><td>verb, past tense</td><td>VerbForm=fin Tense=past</td></tr>\n","<tr><td>VERB</td><td></td><td>VBG</td><td>verb, gerund or present participle</td><td>VerbForm=part Tense=pres Aspect=prog</td></tr>\n","<tr><td>VERB</td><td></td><td>VBN</td><td>verb, past participle</td><td>VerbForm=part Tense=past Aspect=perf</td></tr>\n","<tr><td>VERB</td><td></td><td>VBP</td><td>verb, non-3rd person singular present</td><td>VerbForm=fin Tense=pres</td></tr>\n","<tr><td>VERB</td><td></td><td>VBZ</td><td>verb, 3rd person singular present</td><td>VerbForm=fin Tense=pres Number=sing Person=3</td></tr>\n","<tr><td>X</td><td>other</td><td>ADD</td><td>email</td><td></td></tr>\n","<tr><td>X</td><td></td><td>FW</td><td>foreign word</td><td>Foreign=yes</td></tr>\n","<tr><td>X</td><td></td><td>GW</td><td>additional word in multi-word expression</td><td></td></tr>\n","<tr><td>X</td><td></td><td>XX</td><td>unknown</td><td></td></tr>\n","<tr><td>SPACE</td><td>space</td><td>_SP</td><td>space</td><td></td></tr>\n","<tr><td></td><td></td><td>NIL</td><td>missing tag</td><td></td></tr>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"YOFnL0hJGAAt"},"source":["Here's a link to all the speech tags available through `spaCy`: https://spacy.io/api/annotation#pos-tagging"]},{"cell_type":"markdown","metadata":{"id":"W4Ef0glwGAAt"},"source":["### Working with POS Tags\n","In the English language, the same string of characters can have different meanings, even within the same sentence. For this reason, morphology is important. spaCy uses machine learning algorithms to best predict the use of a token in a sentence. Is \"*I read library books*\" present or past tense? Is *read* a verb or a noun?\n","\n","Lets look at an example."]},{"cell_type":"code","metadata":{"id":"cj8ii6F3GAAt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394758718,"user_tz":0,"elapsed":20,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"a29be606-ca01-4b14-8492-90cda22d2c8b"},"source":["doc_object = nlp(u\"I read library books.\")\n","for word in doc_object:\n","    print(f\" {word.text:{10}} {word.pos_:{10}} {word.tag_:{10}} {spacy.explain(word.tag_):{20}}\")"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":[" I          PRON       PRP        pronoun, personal   \n"," read       VERB       VBP        verb, non-3rd person singular present\n"," library    NOUN       NN         noun, singular or mass\n"," books      NOUN       NNS        noun, plural        \n"," .          PUNCT      .          punctuation mark, sentence closer\n"]}]},{"cell_type":"markdown","metadata":{"id":"YluKnJXgGAAu"},"source":["`spaCy` detects that the word *read* in this sentence is in the *present* tense."]},{"cell_type":"code","metadata":{"id":"qvPpZ1_DGAAu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394758719,"user_tz":0,"elapsed":20,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"f97eded6-2600-4f29-c0e8-94e30b44ce44"},"source":["doc_object = nlp(u\"I recently read a library book.\")\n","for word in doc_object:\n","    print(f\" {word.text:{10}} {word.pos_:{10}} {word.tag_:{10}} {spacy.explain(word.tag_):{20}}\")"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":[" I          PRON       PRP        pronoun, personal   \n"," recently   ADV        RB         adverb              \n"," read       VERB       VBD        verb, past tense    \n"," a          DET        DT         determiner          \n"," library    NOUN       NN         noun, singular or mass\n"," book       NOUN       NN         noun, singular or mass\n"," .          PUNCT      .          punctuation mark, sentence closer\n"]}]},{"cell_type":"markdown","metadata":{"id":"FUwBgXY9GAAu"},"source":["Then it detects that *read* in this example is in the past tense. "]},{"cell_type":"markdown","metadata":{"id":"bxMvAuiTGAAv"},"source":["POS tagging can be useful if we have words or tokens that can have multiple POS tags. For instance, the word \"google\" can be used as both a noun and verb, depending upon the context of the sentence. While processing natural language, it is important to identify this difference. \n","\n","Fortunately, `spaCy` comes pre-built with machine learning algorithms that, depending upon the context (surrounding words), is capable of returning the correct POS tag for the word.\n","\n","Let's have a look at the **google** example."]},{"cell_type":"code","metadata":{"id":"7kHhUsEGGAAv","executionInfo":{"status":"ok","timestamp":1679394758719,"user_tz":0,"elapsed":19,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}}},"source":["doc_object = nlp(u\"Can you google it?\")"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"siFkMzVXGAAw"},"source":["Lets examine the POS tags for the word *google* in this sentence."]},{"cell_type":"code","metadata":{"id":"Y5FTJjehGAAw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394758720,"user_tz":0,"elapsed":20,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"8930d899-e466-4d73-ee9f-9f7834969db7"},"source":["word = doc_object[2]\n","print (word)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["google\n"]}]},{"cell_type":"code","metadata":{"id":"La-RpuQjGAAw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394758720,"user_tz":0,"elapsed":18,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"5f7c1603-4382-4698-b8cb-06f4b184c2c5"},"source":["print(f\" {word.text:{10}} {word.pos_:{10}} {word.tag_:{10}} {spacy.explain(word.tag_):{20}}\")"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":[" google     VERB       VB         verb, base form     \n"]}]},{"cell_type":"markdown","metadata":{"id":"P2W3VRHnGAAw"},"source":["From the output, the word \"google\" has been correctly identified as a verb.\n","\n","Now let's change the context of the sentence."]},{"cell_type":"code","metadata":{"id":"6xf8gJqLGAAw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394758720,"user_tz":0,"elapsed":17,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"ad764e30-89d7-49f6-de74-a33b6980c143"},"source":["doc_object = nlp(u\"Can you search for it on google?\")\n","word = doc_object[6]\n","print(word)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["google\n"]}]},{"cell_type":"code","metadata":{"id":"eaxYHtPPGAAx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394758720,"user_tz":0,"elapsed":16,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"91d64a9c-c2fc-4698-99d5-fe116363d386"},"source":["print(f\" {word.text:{10}} {word.pos_:{10}} {word.tag_:{10}} {spacy.explain(word.tag_):{20}}\")"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":[" google     PROPN      NNP        noun, proper singular\n"]}]},{"cell_type":"markdown","metadata":{"id":"KSvuKl5bGAAx"},"source":["Now the word **google** is being used and detected as a noun."]},{"cell_type":"markdown","metadata":{"id":"qXpwtgpOGAAx"},"source":["## Counting POS Tags\n","\n","The `.count_by()` method accepts a specific token attribute as its argument, and returns a frequency count of the given attribute as a dictionary object. The method takes `spacy.attrs.POS` as a parameter value. \n","\n","Keys in the dictionary are the integer values of the given attribute ID, and values are the frequency. Counts of zero are not included.\n","\n","The `spacy.attrs.POS` command provides information on the **course-grained** POS tag for each word in the document object."]},{"cell_type":"code","metadata":{"id":"EanoxbF1GAAx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394758721,"user_tz":0,"elapsed":17,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"27f15f15-fe8b-497a-cf11-fa4c675a0c18"},"source":["doc_object = nlp(u\"I ate an apple before I went to class. I'm still feeling hungry though.\")\n","\n","# Count the frequencies of different coarse-grained POS tags in the sentence\n","POS_frequency = doc_object.count_by(spacy.attrs.POS)\n","POS_frequency"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{95: 3, 100: 3, 90: 1, 92: 2, 98: 1, 85: 1, 97: 2, 87: 1, 86: 2, 84: 1}"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"VkZP9mnEGAAy"},"source":["In the output, we can see the ID of the POS tags along with their frequencies of occurrence. The text of the POS tag can be displayed by passing the ID of the tag to the vocabulary of the `spaCy` document."]},{"cell_type":"code","metadata":{"id":"hVP0zaOAGAAy","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1679394758721,"user_tz":0,"elapsed":16,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"1104566e-c2bf-40f4-ddeb-a5f6701708dc"},"source":["doc_object.vocab[97].text"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'PUNCT'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"VmGoI7M_GAAy"},"source":["This means that there is *one* punctuation in the sentence.\n","\n","We can use a loop to display the frequency of each POS tag in the sentence. **POS_frequency** is a dictionary object so we need to use the `.items()` command to access each element within it. The content of `POS_frequency` contains the POS tag ID followed by the number of occurrences of that ID. So we assign a variable to each item within the loop. The text of the POS tag can be displayed by passing the ID of the tag to the vocabulary of the spaCy document object. The vocab object provides a lookup table containing lexemes etc. See this link for more information https://spacy.io/api/vocab "]},{"cell_type":"code","metadata":{"id":"Fuf7A91MGAAy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394758721,"user_tz":0,"elapsed":15,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"62a65808-e370-4039-d1b2-d3cbf5d8af5b"},"source":["# Using the \".items()\" command accesses each item in the dictionary\n","for tag_id, occurrences in POS_frequency.items():\n","        print(f\" {tag_id:{10}} {doc_object.vocab[tag_id].text:{10}} {occurrences}\")"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["         95 PRON       3\n","        100 VERB       3\n","         90 DET        1\n","         92 NOUN       2\n","         98 SCONJ      1\n","         85 ADP        1\n","         97 PUNCT      2\n","         87 AUX        1\n","         86 ADV        2\n","         84 ADJ        1\n"]}]},{"cell_type":"markdown","metadata":{"id":"_iCE1trEGAAz"},"source":["We can provide details on the fine-grained POS tag count too.\n","The `spacy.attrs.TAG` command provides information on the *fine-grained* POS tag for each word in the document object."]},{"cell_type":"code","metadata":{"id":"MafcmqrOGAAz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394758721,"user_tz":0,"elapsed":13,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"5a89cd07-5c2a-45ff-9fa1-4e0bfe306665"},"source":["# Get counts on each fine-grained POS tag for the document object\n","fine_grained_POS = doc_object.count_by(spacy.attrs.TAG)\n","\n","for tag_id, occurrences in sorted (fine_grained_POS.items()):\n","    print(f\" {tag_id:{20}} {doc_object.vocab[tag_id].text:{10}} {occurrences}\")"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["   164681854541413346 RB         2\n","  1292078113972184607 IN         2\n","  1534113631682161808 VBG        1\n","  9188597074677201817 VBP        1\n"," 10554686591937588953 JJ         1\n"," 12646065887601541794 .          2\n"," 13656873538139661788 PRP        3\n"," 15267657372422890137 DT         1\n"," 15308085513773655218 NN         2\n"," 17109001835818727656 VBD        2\n"]}]},{"cell_type":"markdown","metadata":{"id":"mE4LLGO8GAAz"},"source":["The output is sorted on the tag ID.\n","\n","We can look at the *syntactic dependencies* of the document object using the `spacy.attrs.dep` command."]},{"cell_type":"code","metadata":{"id":"8NUUyDPWGAA0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394758721,"user_tz":0,"elapsed":12,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"3d995926-786d-4a6d-aaae-4f8175ed8cef"},"source":["# Count the different dependencies:\n","syn_dep_count = doc_object.count_by(spacy.attrs.DEP)\n","\n","for tag_id, occurrences in sorted(syn_dep_count.items()):\n","    print(f'{tag_id:{10}} {doc_object.vocab[tag_id].text:{10}}: {occurrences}')"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["       398 acomp     : 1\n","       399 advcl     : 1\n","       400 advmod    : 2\n","       405 aux       : 1\n","       415 det       : 1\n","       416 dobj      : 1\n","       423 mark      : 1\n","       429 nsubj     : 3\n","       439 pobj      : 1\n","       443 prep      : 1\n","       445 punct     : 2\n","8206900633647566924 ROOT      : 2\n"]}]},{"cell_type":"markdown","metadata":{"id":"hVra9NbwGAA0"},"source":["## Visualizing POS Tags\n","\n","Visualising POS tags in a graphical way is quite easy. The `displacy` module from the Spacy library is used for this purpose. \n","\n","To visualise the POS tags inside the Jupyter notebook, we need to call the `render` method from the `displacy` module and pass the spacy document object to it. We must set the style of the visualisation, and the `jupyter` attribute to `True`. I've already covered visualisation in the **Tokenisation** lecture so refer to it for further information. "]},{"cell_type":"code","metadata":{"id":"7a7ZssFXGAA0","colab":{"base_uri":"https://localhost:8080/","height":313},"executionInfo":{"status":"ok","timestamp":1679394758722,"user_tz":0,"elapsed":12,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"053e2d65-88c9-4e98-8b39-afd9faadee71"},"source":["from spacy import displacy\n","\n","doc_object = nlp(u\"I ate an apple before I went to class. I'm still feeling hungry though.\")\n","displacy.render(doc_object, style='dep', jupyter=True, options={'distance': 90})"],"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"fd45267863714c5991e35d93b807f220-0\" class=\"displacy\" width=\"1400\" height=\"272.0\" direction=\"ltr\" style=\"max-width: none; height: 272.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">ate</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">VERB</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">an</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">DET</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">apple</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">NOUN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">before</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">SCONJ</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">I</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">PRON</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">went</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">VERB</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">to</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">ADP</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">class.</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">NOUN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">I</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">PRON</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">'m</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">AUX</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">still</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">ADV</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">feeling</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">VERB</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1220\">hungry</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1220\">ADJ</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1310\">though.</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1310\">ADV</tspan>\n","</text>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-fd45267863714c5991e35d93b807f220-0-0\" stroke-width=\"2px\" d=\"M70,137.0 C70,92.0 130.0,92.0 130.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-fd45267863714c5991e35d93b807f220-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M70,139.0 L62,127.0 78,127.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-fd45267863714c5991e35d93b807f220-0-1\" stroke-width=\"2px\" d=\"M250,137.0 C250,92.0 310.0,92.0 310.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-fd45267863714c5991e35d93b807f220-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M250,139.0 L242,127.0 258,127.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-fd45267863714c5991e35d93b807f220-0-2\" stroke-width=\"2px\" d=\"M160,137.0 C160,47.0 315.0,47.0 315.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-fd45267863714c5991e35d93b807f220-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M315.0,139.0 L323.0,127.0 307.0,127.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-fd45267863714c5991e35d93b807f220-0-3\" stroke-width=\"2px\" d=\"M430,137.0 C430,47.0 585.0,47.0 585.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-fd45267863714c5991e35d93b807f220-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M430,139.0 L422,127.0 438,127.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-fd45267863714c5991e35d93b807f220-0-4\" stroke-width=\"2px\" d=\"M520,137.0 C520,92.0 580.0,92.0 580.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-fd45267863714c5991e35d93b807f220-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M520,139.0 L512,127.0 528,127.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-fd45267863714c5991e35d93b807f220-0-5\" stroke-width=\"2px\" d=\"M160,137.0 C160,2.0 590.0,2.0 590.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-fd45267863714c5991e35d93b807f220-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M590.0,139.0 L598.0,127.0 582.0,127.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-fd45267863714c5991e35d93b807f220-0-6\" stroke-width=\"2px\" d=\"M610,137.0 C610,92.0 670.0,92.0 670.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-fd45267863714c5991e35d93b807f220-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M670.0,139.0 L678.0,127.0 662.0,127.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-fd45267863714c5991e35d93b807f220-0-7\" stroke-width=\"2px\" d=\"M700,137.0 C700,92.0 760.0,92.0 760.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-fd45267863714c5991e35d93b807f220-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M760.0,139.0 L768.0,127.0 752.0,127.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-fd45267863714c5991e35d93b807f220-0-8\" stroke-width=\"2px\" d=\"M880,137.0 C880,2.0 1130.0,2.0 1130.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-fd45267863714c5991e35d93b807f220-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M880,139.0 L872,127.0 888,127.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-fd45267863714c5991e35d93b807f220-0-9\" stroke-width=\"2px\" d=\"M970,137.0 C970,47.0 1125.0,47.0 1125.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-fd45267863714c5991e35d93b807f220-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M970,139.0 L962,127.0 978,127.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-fd45267863714c5991e35d93b807f220-0-10\" stroke-width=\"2px\" d=\"M1060,137.0 C1060,92.0 1120.0,92.0 1120.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-fd45267863714c5991e35d93b807f220-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M1060,139.0 L1052,127.0 1068,127.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-fd45267863714c5991e35d93b807f220-0-11\" stroke-width=\"2px\" d=\"M1150,137.0 C1150,92.0 1210.0,92.0 1210.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-fd45267863714c5991e35d93b807f220-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M1210.0,139.0 L1218.0,127.0 1202.0,127.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-fd45267863714c5991e35d93b807f220-0-12\" stroke-width=\"2px\" d=\"M1150,137.0 C1150,47.0 1305.0,47.0 1305.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-fd45267863714c5991e35d93b807f220-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M1305.0,139.0 L1313.0,127.0 1297.0,127.0\" fill=\"currentColor\"/>\n","</g>\n","</svg></span>"]},"metadata":{}}]},{"cell_type":"markdown","source":["## Exercise: Lemmatisation and Sentiment Analysis of IMDB Data\n","\n","To get some hands on experience of applying the above techniques, we'll lemmatise the IMDB database we saw in the previous class. Then we'll use the Scattertext library to visualise the sentiment of words in the corpus based on the positive/negative classification of each review.\n","\n","First, install Scattertext and examine the interactive plot produced in `demo.html` by the code below. This uses a sample corpus of US Democratic and Republican political speeches. \n","\n","Note that Scattertext takes a Pandas DataFrame as input."],"metadata":{"id":"6iv8Y4dMSQCC"}},{"cell_type":"code","source":["%%capture\n","!pip install scattertext"],"metadata":{"id":"4Uy2zD8JSaHZ","executionInfo":{"status":"ok","timestamp":1679394769590,"user_tz":0,"elapsed":10879,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import scattertext as st\n","from scattertext import produce_scattertext_explorer\n","\n","data = st.SampleCorpora.ConventionData2012.get_data().assign(\n","    parse=lambda df: df.text.apply(st.whitespace_nlp_with_sentences)\n",")\n","data.head()"],"metadata":{"id":"ArM7f4wSSj1r","colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"status":"ok","timestamp":1679394777271,"user_tz":0,"elapsed":7684,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"f10105d0-f4c5-4da8-cd5c-3057b9419ca9"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      party                                               text  \\\n","0  democrat  Thank you. Thank you. Thank you. Thank you so ...   \n","1  democrat  Thank you so much. Tonight, I am so thrilled a...   \n","2  democrat  Thank you. It is a singular honor to be here t...   \n","3  democrat  Hey, Delaware. \\nAnd my favorite Democrat, Jil...   \n","4  democrat  Hello. \\nThank you, Angie. I'm so proud of how...   \n","\n","          speaker                                              parse  \n","0    BARACK OBAMA  (thank, you, ., thank, you, ., thank, you, ., ...  \n","1  MICHELLE OBAMA                          (thank, you, so, much, .)  \n","2  RICHARD DURBIN  (thank, you, ., it, is, a, singular, honor, to...  \n","3    JOSEPH BIDEN  (hey, ,, delaware, ., and, my, favorite, democ...  \n","4      JILL BIDEN  (hello, ., thank, you, ,, angie, ., i, ', m, s...  "],"text/html":["\n","  <div id=\"df-6c068e2c-1ec0-43b8-9f75-3783a5c62b04\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>party</th>\n","      <th>text</th>\n","      <th>speaker</th>\n","      <th>parse</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>democrat</td>\n","      <td>Thank you. Thank you. Thank you. Thank you so ...</td>\n","      <td>BARACK OBAMA</td>\n","      <td>(thank, you, ., thank, you, ., thank, you, ., ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>democrat</td>\n","      <td>Thank you so much. Tonight, I am so thrilled a...</td>\n","      <td>MICHELLE OBAMA</td>\n","      <td>(thank, you, so, much, .)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>democrat</td>\n","      <td>Thank you. It is a singular honor to be here t...</td>\n","      <td>RICHARD DURBIN</td>\n","      <td>(thank, you, ., it, is, a, singular, honor, to...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>democrat</td>\n","      <td>Hey, Delaware. \\nAnd my favorite Democrat, Jil...</td>\n","      <td>JOSEPH BIDEN</td>\n","      <td>(hey, ,, delaware, ., and, my, favorite, democ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>democrat</td>\n","      <td>Hello. \\nThank you, Angie. I'm so proud of how...</td>\n","      <td>JILL BIDEN</td>\n","      <td>(hello, ., thank, you, ,, angie, ., i, ', m, s...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c068e2c-1ec0-43b8-9f75-3783a5c62b04')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6c068e2c-1ec0-43b8-9f75-3783a5c62b04 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6c068e2c-1ec0-43b8-9f75-3783a5c62b04');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["corpus = st.CorpusFromParsedDocuments(data, category_col='party', \n","                                      parsed_col='parse').build()\n","html = st.produce_scattertext_explorer(corpus, category='democrat', \n","                                       category_name='Democratic', \n","                                       not_category_name='Republican', \n","                                       minimum_term_frequency=5, \n","                                       width_in_pixels=1000)\n","open('./demo.html', 'w').write(html);"],"metadata":{"id":"Yjl8nJCAcuCl","executionInfo":{"status":"ok","timestamp":1679394782034,"user_tz":0,"elapsed":2539,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["Now, create a similar visualisation for the positive and negative reviews contained in the IMDB database. To see the difference made by lemmatisation, try creating visualisation for before and after. What other techniques could improve the output?\n","\n","To ensure your code doesn't take too long to run, restrict your analysis to the first 1000 reviews."],"metadata":{"id":"nJND70h-TF1u"}},{"cell_type":"code","source":[],"metadata":{"id":"-N6BRHOnSehb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Td4NwiH0Sgbg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"asWu4x08VKcE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bfXynxy1VMNl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9FXHh5kjYNV7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8A7paywdZRKj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DoAA7hVFZtT3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Examine the output."],"metadata":{"id":"EaNh3B6hWSBz"}}]}
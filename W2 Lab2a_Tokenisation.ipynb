{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"RJPjhhW6gtYP"},"source":[" *Artificial Intelligence for Vision & NLP* &nbsp; | &nbsp;  *ATU Donegal - MSc in Big Data Analytics & Artificial Intelligence*\n","\n","# Tokenisation\n","The first step in creating a `Doc` object is to break down the incoming text into component pieces or *tokens*.\n","\n","Let's look at the first example shown in the lecture."]},{"cell_type":"code","metadata":{"id":"o4xuSJr5gtYR"},"source":["# Import spaCy and load the English language library\n","import spacy\n","# This will take a while to load initially\n","nlp = spacy.load(\"en_core_web_sm\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zn59mFykgtYS"},"source":["# The text is within \"\" which we want to display and therefore we need to use \n","# the \\ character to identify that some of the single quote marks are not the \n","# end of the sentence\n","\n","# SpaCy works with doc objects. This doc object is called \"sentence\"\n","sentence = '\"Mr. O\\'Neill thinks that the boys\\' stories about Chile\\'s capital aren\\'t amusing.\"'\n","print(sentence)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zkj-lPkogtYT"},"source":["Now we'll examine each of the tokens for our sentence. Refer to the slides on Blackboard for further information."]},{"cell_type":"code","metadata":{"id":"eqEtCMyKgtYT"},"source":["nlp_sentence = nlp(sentence)\n","for token in nlp_sentence:\n","    print(token.text)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NNgoXOBcgtYU"},"source":["Note that the sentence is split on punctuation, and the word **boys'** , **Chile's** and **aren't** are now split and are assigned their own tokens. The prefix and suffix have also been assigned individual tokens. The **.** for the word **Mr.** has remained part of this word. SpaCy was able to determine that the **.** is part of the **Mr.** title."]},{"cell_type":"code","metadata":{"id":"m2ZegaYagtYU"},"source":["nlp_sentence = nlp(sentence)\n","\n","# Show the tokens of the sentence and use\n","# the \"|\" between each token for additional clarification\n","for token in nlp_sentence:\n","    print(token.text, token.pos_, end = \" | \")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uyeJoxoxgtYV"},"source":["Lets look at a more difficult sentence that includes **.** within the time elements, and **.** within the web address."]},{"cell_type":"code","metadata":{"id":"YYnc6CcdgtYV"},"source":["sentence = \"It is best to access our website from 9 a.m. to 1 p.m. every weekend. The address is www.mywebsite.ie.\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZvnZ55uYgtYV"},"source":["doc_object = nlp(sentence)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zPhbHTZEgtYW"},"source":["for token in doc_object:\n","    print(token)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9B98Ux3IgtYW"},"source":["SpaCy tokenises all words as expected, including the `.`. It also separates out the `.` at the end of the sentence as a *suffix* compared to the `.` in the middle of the web address.\n","\n","Spacy can detect the difference between units such as distance and cost. Here's an example."]},{"cell_type":"code","metadata":{"id":"WIL3NdFDgtYW"},"source":["sentence = \"I live about 20km from here. A taxi will cost around £50.\"\n","doc_object = nlp(sentence)\n","\n","for token in doc_object:\n","    print(token)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6UB7VOxMgtYd"},"source":["## Counting Tokens\n","`Doc` objects have a set number of tokens:"]},{"cell_type":"code","metadata":{"id":"PvyDz1-xgtYd"},"source":["# Number of tokens in our sentence\n","len(doc_object)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DNzSHqdbgtYe"},"source":["A language library contains individual `vocab` objects. The number of vocab objects in a library can vary for each language and can change when we add new `vocab` objects called `lexemes` to a language library."]},{"cell_type":"code","metadata":{"id":"1ttMbfT-gtYe"},"source":["# Count the number of vocab objects in the currently loaded language library\n","# This is from the en_core_web_sm library\n","# Use en_core_web_lg for larger library\n","len(doc_object.vocab)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EyjyOcsygtYe"},"source":["## Retrieve token by index position and slice\n","`Doc` objects can be thought of as lists of `token` objects. As such, individual tokens can be retrieved by index position, and spans of tokens can be retrieved through slicing, just as shown in the previous notebook.\n","\n","Let's enter the text into a `doc` object and then show the contents of the sentence."]},{"cell_type":"code","metadata":{"id":"vqvB4nC7gtYe"},"source":["doc = nlp(u\"I really like working with words!\")\n","\n","# Print each token\n","for token in doc:\n","    print(token)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R7XNdZJagtYf"},"source":["Now we can extract some tokens from the sentence. Note that the indexer starts at 0, and all tokens such as suffix count as a token position."]},{"cell_type":"code","metadata":{"id":"3jKoWABRgtYf"},"source":["# Retrieve the first token\n","doc[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X-6A1FibgtYf"},"source":["# Retrieve the 3rd to 6th token\n","doc[3:6]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o0-c2O8tgtYf"},"source":["# Retrieve the last 2 tokens\n","doc[-2:]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zruTmu2XgtYg"},"source":["We cannot re-assign individual tokens with new values. Remember that Spacy has already done a lot of calculations on your text, so an item reassignment is going to cause issues with these."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"mf8IEnF3gtYg"},"source":["doc[2] = \"Do not\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EELXbLtEgtYg"},"source":["# Named Entity Recognition (NER)\n","Going a step beyond tokens, **named entities** add another layer of context. A named entity is a **real-world object** that’s assigned a name – for example, a person, a country, a product, a date, money, a book title etc.\n","\n","spaCy can recognise various types of named entities in a document, by asking the language model for a prediction.\n","\n","Named entities are accessible through the `ents` property of a `Doc` object."]},{"cell_type":"code","metadata":{"id":"2pIeni93gtYh"},"source":["doc_object = nlp(u\"Samsung in Ireland are pleased with their new folding screen that they released after a large $9 million investment.\")\n","\n","for token in doc_object:\n","    # show the token followed by a separator\n","    print (token, end = \" | \")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-StLC_STgtYh"},"source":["We can view the named entities in the doc object with the following code:"]},{"cell_type":"code","metadata":{"id":"F52WoCX_gtYh"},"source":["for entity in doc_object.ents:\n","    print (entity)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h3jVVhUXgtYh"},"source":["SpaCy has recognised that these tokens are named entities and there are more context to these tokens. They are similar to nouns.\n","\n","We can view the label for each named entity and see what entity spaCy has assigned to each named entity."]},{"cell_type":"code","metadata":{"id":"CraSLUxMgtYi"},"source":["for entity in doc_object.ents:\n","    # Show the entity and its general label\n","    print (entity, entity.label_)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UK7S-8H3gtYi"},"source":["We can show more detail on each entity label. All this is generated automatically through spaCy."]},{"cell_type":"code","metadata":{"id":"mq05mlJCgtYi"},"source":["for entity in doc_object.ents:\n","    # Show the entity and its general label\n","    # and show a full description on each named entity\n","    # using the spacy.explain command\n","    print (entity, entity.label_, spacy.explain(entity.label_))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"USW1ttvAgtYi"},"source":["If a named entity does not exist, the `show_ents` function will not work. For example, the word **car** is not automatically recognised as a named entity."]},{"cell_type":"code","metadata":{"id":"P5w-dc9egtYi"},"source":["doc_object = nlp(u\"I like my car\")\n","for entity in doc_object.ents:\n","    # Show the entity and its general label\n","    print (entity, entity.label_)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CvS36MgKgtYj"},"source":["Next we create a new function called `show_entity_info` that will accept a `doc_object` and display relevant entity information. I'll also check whether entity information exists or not."]},{"cell_type":"code","metadata":{"id":"XiphD9cAgtYj"},"source":["# Create a function to display entity information from a doc_object\n","def show_entity_info(doc_object):\n","    if doc_object:\n","        for entity in doc_object.ents:\n","            print(f\"{entity.text} {entity.label_:{20}} {spacy.explain(entity.label_)}\")\n","    else:\n","        print(f\"No entities found in text.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o9ISfNTqiXDt"},"source":["doc_object = nlp(u\"Samsung in Ireland are pleased with their new folding screen that they released after a large $9 million investment.\")\n","show_entity_info(doc_object)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zKu6rsq7gtYj"},"source":["# Noun Chunks\n","Similar to NER `Doc.ents`, `Doc.noun_chunks` are another object property. *Noun chunks* are **base noun phrases** – flat phrases that have a noun as their head. You can think of noun chunks as a noun plus the words describing the noun – for example, a *\"the lavish green grass\"* would be one noun chunk.\n","\n","`spaCy` uses the terms **head** and **child** to describe the words connected by a single arc in the **dependency tree**. The term **dep** is used for the arc label, which describes the type of syntactic relation that connects the child to the head. \n","\n","Lets have a look at an example. I'll then demonstrate how we can use a visualiser to demonstrate this information. "]},{"cell_type":"code","metadata":{"id":"DIztLjjlgtYk"},"source":["doc_object = nlp(\"Autonomous cars shift insurance liability toward manufacturers\")\n","\n","# Create header text for table output\n","column1 = \"Text\"\n","column2 = \"Root text\"\n","column3 = \"Root dependency\"\n","column4 = \"Root head text\"\n","# Show the header for the table output\n","print (f\"{column1:25} {column2:20} {column3:25} {column4:20}\")\n","# Show relevant detail for each noun chunk in the text\n","for chunk in doc_object.noun_chunks:\n","    print(f\"{chunk.text:{25}} {chunk.root.text:{20}} {spacy.explain(chunk.root.dep_):{25}} {chunk.root.head.text:{20}}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Iy0meVVggtYk"},"source":["The noun *cars* is described by the word *autonomous*. Both words are referred to as a *noun chunk*. Similarly the  noun *liability* is described by the word *insurance*. So again both words are described as a *noun chunk*. *Insurance* is a noun, and is also called a *noun chunk* even though it does not have any descriptive text associated with it.\n","\n","In the table above, the *Text* column represents the original noun chunk text. The *Root text* column is the original text of the word connecting the noun chunk to the rest of the parse.\n","\n","The *Root dependency* column is the dependency relation connecting the root to its head. The *Root head text* is the text of the root token’s head.\n","\n","For more info on *noun_chunks*, see https://spacy.io/usage/linguistic-features#noun-chunks"]},{"cell_type":"markdown","metadata":{"id":"izyJg0lagtYk"},"source":["## displaCy Built-in Visualiser\n","\n","spaCy includes a built-in visualisation tool called `displaCy`. `displaCy` is able to detect whether you're working in a Jupyter notebook, and will return markup that can be rendered in a cell right away. When you export your notebook, the visualizations will be included as HTML.\n","\n","Let's examine the dependencies of our sentence visually.\n","\n","Note that we can show the sentence dependencies using the `style=\"dep\"` option and the sentence entities using the `style=\"ent\"` option."]},{"cell_type":"code","metadata":{"id":"80WpSoeBgtYl"},"source":["from spacy import displacy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i6Abv2IjgtYl"},"source":["doc_object = nlp(u\"Autonomous cars shift insurance liability toward manufacturers\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tzURAgGrgtYl"},"source":["# Command to display the sentence. Be careful of the case with the word \"True\"\n","# Style set to \"dep\" means display dependencies\n","displacy.render(doc_object, style=\"dep\", jupyter=True, options={\"distance\":100} )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fsy985C0gtYm"},"source":["The `options` command in the `dispacy.render` function allows us to modify various things in the diagram that is output by the visualisation tool. Here's a list of the settings availabe to us. See also this link for more information on the dispacy visualiser: https://spacy.io/api/top-level#displacy_options"]},{"cell_type":"markdown","metadata":{"id":"GIr8VeaegtYm"},"source":["<tr class=\"_8a68569b\"><th class=\"_2e8d2972\">Name</th><th class=\"_2e8d2972\">Type</th><th class=\"_2e8d2972\">Description</th><th class=\"_2e8d2972\">Default</th></tr>\n","\n","<tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">fine_grained</code></td><td class=\"_5c99da9a\">bool</td><td class=\"_5c99da9a\">Use fine-grained part-of-speech tags (<code class=\"_1d7c6046\">Token.tag_</code>) instead of coarse-grained tags (<code class=\"_1d7c6046\">Token.pos_</code>).</td><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">False</code></td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">collapse_punct</code></td><td class=\"_5c99da9a\">bool</td><td class=\"_5c99da9a\">Attach punctuation to tokens. Can make the parse more readable, as it prevents long arcs to attach punctuation.</td><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">True</code></td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">collapse_phrases</code></td><td class=\"_5c99da9a\">bool</td><td class=\"_5c99da9a\">Merge noun phrases into one token.</td><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">False</code></td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">compact</code></td><td class=\"_5c99da9a\">bool</td><td class=\"_5c99da9a\">“Compact mode” with square arrows that takes up less space.</td><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">False</code></td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">color</code></td><td class=\"_5c99da9a\">unicode</td><td class=\"_5c99da9a\">Text color (HEX, RGB or color names).</td><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">'#000000'</code></td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">bg</code></td><td class=\"_5c99da9a\">unicode</td><td class=\"_5c99da9a\">Background color (HEX, RGB or color names).</td><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">'#ffffff'</code></td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">font</code></td><td class=\"_5c99da9a\">unicode</td><td class=\"_5c99da9a\">Font name or font family for all text.</td><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">'Arial'</code></td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">offset_x</code></td><td class=\"_5c99da9a\">int</td><td class=\"_5c99da9a\">Spacing on left side of the SVG in px.</td><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">50</code></td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">arrow_stroke</code></td><td class=\"_5c99da9a\">int</td><td class=\"_5c99da9a\">Width of arrow path in px.</td><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">2</code></td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">arrow_width</code></td><td class=\"_5c99da9a\">int</td><td class=\"_5c99da9a\">Width of arrow head in px.</td><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">10</code> / <code class=\"_1d7c6046\">8</code> (compact)</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">arrow_spacing</code></td><td class=\"_5c99da9a\">int</td><td class=\"_5c99da9a\">Spacing between arrows in px to avoid overlaps.</td><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">20</code> / <code class=\"_1d7c6046\">12</code> (compact)</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">word_spacing</code></td><td class=\"_5c99da9a\">int</td><td class=\"_5c99da9a\">Vertical spacing between words and arcs in px.</td><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">45</code></td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">distance</code></td><td class=\"_5c99da9a\">int</td><td class=\"_5c99da9a\">Distance between words in px.</td><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">175</code> / <code class=\"_1d7c6046\">150</code> (compact)</td></tr>"]},{"cell_type":"markdown","metadata":{"id":"yXQedDx-gtYm"},"source":["In the example above, we set the `distance` option to **100**. That set the pixel distance to **100** between each word on the diagram."]},{"cell_type":"markdown","metadata":{"id":"NlQYGv07gtYn"},"source":["Here's another example showing various options from the table above. Note that the change from circular to square lines on the diagram can be achieved with the `compact` option."]},{"cell_type":"code","metadata":{"id":"YgFSOvzNgtYn"},"source":["displacy.render(doc_object, style=\"dep\", jupyter=True, options={\"distance\":130, \"color\":\"Blue\", \"arrow_stroke\":4, \"arrow_spacing\":20, \"word_spacing\":50, \"compact\":True} )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dDAKvhbegtYo"},"source":["Earlier we examined the dependencies in the sentence. `dispacy` can also display the entities of the sentence by using the `style=\"ent\"` option. Before we do that, lets look at whether there are any entities in the sentence we've been using in the example until now."]},{"cell_type":"code","metadata":{"id":"VTZfelDsgtYo"},"source":["# Display any named entities in the string\n","for entity in doc_object.ents:\n","    print (entity)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MdPHu2ZGgtYo"},"source":["There are no named entities, so we'll use another text example for demo purposes. \n","\n","The text in this example comes from the official `displacy` webpage. For more info, see https://explosion.ai/demos/displacy-ent\n","\n","First I'll look at the entities in this sentence."]},{"cell_type":"code","metadata":{"id":"OSrz-EXkgtYp"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","file_name = open(\"/content/gdrive/My Drive/NLP/noun-chunks.txt\")\n","#sentence = file_name.read()\n","# sentence = (u\"When Sebastian Thrun started working on self-driving cars at \\\n","#              Google in 2007, few people outside of the company took him \\\n","#              seriously. “I can tell you very senior CEOs of major American \\\n","#              car companies would shake my hand and turn away because I \\\n","#              wasn’t worth talking to,” said Thrun, now the co-founder \\\n","#              and CEO of online higher education startup Udacity, in an \\\n","#              interview with Recode earlier this week. A little less than \\\n","#              a decade later, dozens of self-driving startups have cropped \\\n","#              up while automakers around the world clamor, wallet in hand, \\\n","#              to secure their place in the fast-moving world of fully \\\n","#              automated transportation.\")\n","doc_object = nlp(sentence)\n","\n","# Display any named entities in the string\n","for entity in doc_object.ents:\n","    print (entity, entity.label_)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G3QbSV4fgtYp"},"source":["A nice feature in `dispacy.render` function is to display the sentence text and also highlight each entity with its associated entity label. This is all done automatically. "]},{"cell_type":"code","metadata":{"id":"4w7edAfngtYp"},"source":["displacy.render(doc_object, style=\"ent\", jupyter=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Tweet Tokenisation\n","\n","NLTK has a tweet tokeniser module called `nltk.tokenize.TweetTokenizer`. Find out how to use this and use it to create a function that returns a tokenised tweet with any Twitter handles removed. Try also using a regex query to remove the handles."],"metadata":{"id":"m0cNQ6kWZgGM"}},{"cell_type":"code","source":[],"metadata":{"id":"OCMzLcr8Z9lh"},"execution_count":null,"outputs":[]}]}
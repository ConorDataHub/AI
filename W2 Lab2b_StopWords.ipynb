{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"59ElgU0_lnTv"},"source":[" *Artificial Intelligence for Vision & NLP* &nbsp; | &nbsp;  *ATU Donegal - MSc in Big Data Analytics & Artificial Intelligence*\n"," \n","# Stop Words\n","\n","In this practical we will explore removing stop words using the NLTK and SpaCy libraries."]},{"cell_type":"code","metadata":{"id":"VwlH72Pjlk3B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678911827645,"user_tz":0,"elapsed":2808,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"2665a670-d84a-4d4b-8650-941370054b9c"},"source":["import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","source":["text = \"Paul likes to write code in Python, however he is not too fond of C++.\"\n","text_tokens = word_tokenize(text)\n","\n","tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n","\n","print(tokens_without_sw)"],"metadata":{"id":"zt-Qe8EqhFcG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678911827646,"user_tz":0,"elapsed":8,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"c040d024-5257-4868-b564-1dd6b72d483d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["['Paul', 'likes', 'write', 'code', 'Python', ',', 'fond', 'C++', '.']\n"]}]},{"cell_type":"markdown","metadata":{"id":"_7YZG85omPNB"},"source":["In this example you can see that 'to', 'in', 'he', 'is', 'not', 'too', 'of' have been removed from the text. These tokens can also be joined to output a full sentence:"]},{"cell_type":"code","metadata":{"id":"QvPZlkZKmhXl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678911827646,"user_tz":0,"elapsed":5,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"d1e82a7a-006b-46ba-a5fc-a036eed8809e"},"source":["filtered_sentence = (\" \").join(tokens_without_sw)\n","print(filtered_sentence)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Paul likes write code Python , fond C++ .\n"]}]},{"cell_type":"markdown","metadata":{"id":"SojoqR8JmsGs"},"source":["It is possible to add words to the 'stop words' list, you can also print the current list of stop words."]},{"cell_type":"code","metadata":{"id":"NMbtctPfmrmA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678911828127,"user_tz":0,"elapsed":484,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"2c77fafa-0f66-47a8-ed82-077697888541"},"source":["print(len(stopwords.words('english')))\n","print(stopwords.words('english'))"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["179\n","['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"]}]},{"cell_type":"markdown","metadata":{"id":"8JDR3y9Nm8O6"},"source":["In the example provided, if we wanted to add the word 'write' as a stop word, we can do this using the following code:"]},{"cell_type":"code","metadata":{"id":"s37Q97tHnLKO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678911828128,"user_tz":0,"elapsed":9,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"b1595158-a8c5-4ef1-d2fb-eb92b45e7e47"},"source":["all_stopwords = stopwords.words('english')\n","all_stopwords.append('write')\n","\n","text_tokens = word_tokenize(text)\n","tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n","\n","print(tokens_without_sw)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["['Paul', 'likes', 'code', 'Python', ',', 'however', 'fond', 'C++', '.']\n"]}]},{"cell_type":"markdown","metadata":{"id":"k5Xh94uZnZlN"},"source":["We can also add a list of stop words using the following code:"]},{"cell_type":"code","metadata":{"id":"Wp2G-G4hncdg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678911828128,"user_tz":0,"elapsed":7,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"ac74506c-0248-497d-bfdf-be9b39f67b5b"},"source":["sw_list = ['likes', 'write']\n","all_stopwords.extend(sw_list)\n","\n","text_tokens = word_tokenize(text)\n","tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n","\n","print(tokens_without_sw)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["['Paul', 'code', 'Python', ',', 'however', 'fond', 'C++', '.']\n"]}]},{"cell_type":"markdown","metadata":{"id":"7mb-2oMZnrYQ"},"source":["In this case, removing the word 'not' changes the meaning of the sentence. If we want to remove a stop word, this can be completed using the following code:"]},{"cell_type":"code","metadata":{"id":"dt7RyxCvnypa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678911828128,"user_tz":0,"elapsed":5,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"fc3515c1-20ad-49a1-fe69-4ab980be7adf"},"source":["all_stopwords = stopwords.words('english')\n","all_stopwords.remove('not')\n","\n","text_tokens = word_tokenize(text)\n","tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n","\n","print(tokens_without_sw)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["['Paul', 'likes', 'write', 'code', 'Python', ',', 'however', 'not', 'fond', 'C++', '.']\n"]}]},{"cell_type":"markdown","metadata":{"id":"dmrk2PmRn-k4"},"source":["Now we will try completing the same tasks using SpaCy."]},{"cell_type":"code","source":["# Import spaCy and load the English language library\n","import spacy\n","# This will take a while to load initially\n","sp = spacy.load(\"en_core_web_sm\")\n","all_stopwords = sp.Defaults.stop_words"],"metadata":{"id":"Ge_PuKrVhgw9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678911850135,"user_tz":0,"elapsed":22011,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"4639874c-6177-476c-c889-a5025ef4ee48"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n"]}]},{"cell_type":"code","metadata":{"id":"PuzlfHfGoB6b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678911850142,"user_tz":0,"elapsed":26,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"64465224-db5b-4842-b3a0-84680668bdab"},"source":["text = \"Paul likes to write code in Python, however he is not too fond of C++.\"\n","text_tokens = word_tokenize(text)\n","tokens_without_sw= [word for word in text_tokens if not word in all_stopwords]\n","\n","print(tokens_without_sw)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["['Paul', 'likes', 'write', 'code', 'Python', ',', 'fond', 'C++', '.']\n"]}]},{"cell_type":"markdown","metadata":{"id":"9TLTqhEcoppT"},"source":["In SpaCy there are more stop words defined, 326 stop words compared to the 179 in NLTK."]},{"cell_type":"code","metadata":{"id":"MiFM5BmMomUD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678911850142,"user_tz":0,"elapsed":24,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"e9c9c293-166a-44c8-f283-b9f6249d1d1f"},"source":["print(len(all_stopwords))\n","print(all_stopwords)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["326\n","{'using', 'per', 're', 'sometimes', 'about', 'well', 'something', 'very', 'he', 'quite', 'everything', 'then', 'out', 'below', 'eleven', 'noone', 'go', 'so', 'they', 'whence', 'â€™m', 'next', 'whither', 'more', 'an', 'nâ€˜t', 'most', 'along', 'why', 'if', 'â€˜m', 'many', 'whole', 'third', 'another', 'done', 'sixty', 'had', 'via', 'except', 'name', 'beside', 'other', 'take', 'â€˜d', 'because', 'moreover', 'somehow', 'own', 'sometime', 'therein', 'never', 'former', 'before', 'someone', 'yourself', 'five', 'thus', 'serious', 'thence', 'alone', 'ten', 'amongst', 'themselves', 'over', 'can', 'forty', 'have', 'herself', 'one', 'see', 'toward', 'and', 'itself', 'with', 'now', 'thereupon', 'such', 'none', 'was', 'for', 'either', 'wherein', 'empty', \"'re\", 'may', 'nobody', 'â€™ve', 'anywhere', 'every', 'others', 'due', 'i', 'when', 'regarding', 'hers', 'though', 'show', 'must', 'nâ€™t', 'without', 'â€˜ve', 'seems', 'six', 'ca', 'throughout', 'yours', 'my', 'whoever', 'everywhere', 'those', 'indeed', 'off', 'whereupon', 'often', 'formerly', 'move', 'rather', 'even', 'our', 'put', 'did', 'nor', 'doing', 'part', 'towards', 'all', 'cannot', 'to', 'at', 'twenty', 'namely', 'few', 'anyway', 'both', 'within', 'further', 'â€˜ll', 'the', 'me', 'from', 'hundred', 'will', 'mine', 'hereupon', 'first', \"'d\", 'always', 'around', 'front', 'unless', 'upon', 'of', 'neither', 'your', 'fifty', 'each', 'less', 'various', 'once', 'still', 'anyone', 'last', 'were', 'this', 'there', 'him', 'does', 'on', 'anything', 'yourselves', 'hereby', 'himself', 'is', 'it', 'any', 'too', 'two', 'than', 'or', 'as', 'her', 'beyond', 'however', 'its', 'wherever', 'side', \"'m\", 'â€™s', 'up', 'becoming', 'been', 'amount', 'nowhere', 'between', 'â€˜s', 'just', 'although', 'else', 'hence', 'four', 'under', 'his', 'ours', 'anyhow', 'could', \"'ve\", 'again', 'get', 'somewhere', 'into', 'herein', 'latter', 'in', 'thereby', 'elsewhere', 'whereby', 'whose', 'full', 'these', 'that', 'enough', 'already', 'least', 'thereafter', 'much', 'through', 'some', 'become', 'who', 'otherwise', 'together', 'twelve', \"n't\", 'hereafter', 'seem', 'whatever', 'fifteen', 'made', 'bottom', 'might', 'back', 'nine', 'same', 'after', 'mostly', 'no', 'yet', 'ever', 'nothing', 'their', 'â€™re', 'you', 'are', \"'ll\", 'should', 'used', 'whom', 'becomes', 'during', 'thru', 'where', 'almost', 'by', 'â€˜re', 'â€™ll', 'beforehand', 'being', 'became', 'myself', 'she', 'besides', 'am', 'above', 'against', 'whereas', 'top', 'has', 'would', 'call', 'please', 'be', 'here', 'say', 'afterwards', 'not', 'therefore', 'a', 'down', 'we', 'seemed', 'also', 'keep', 'across', 'since', 'do', 'everyone', 'nevertheless', 'eight', 'latterly', 'really', 'behind', 'among', 'give', 'until', 'us', 'which', \"'s\", 'onto', 'while', 'three', 'make', 'meanwhile', 'ourselves', 'â€™d', 'only', 'whenever', 'but', 'them', 'what', 'perhaps', 'several', 'how', 'whereafter', 'whether', 'seeming'}\n"]}]},{"cell_type":"markdown","metadata":{"id":"RU0f0gOho6U9"},"source":["It is also possible to add stop words either individually or through using an array:"]},{"cell_type":"code","metadata":{"id":"-I0vp7SQo9G-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678911850142,"user_tz":0,"elapsed":22,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"325a0080-2c26-48d4-f788-02301c19a622"},"source":["all_stopwords = sp.Defaults.stop_words\n","all_stopwords.add(\"C++\")\n","\n","text = \"Paul likes to write code in Python, however he is not too fond of C++.\"\n","text_tokens = word_tokenize(text)\n","tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n","\n","print(tokens_without_sw)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["['Paul', 'likes', 'write', 'code', 'Python', ',', 'fond', '.']\n"]}]},{"cell_type":"markdown","metadata":{"id":"3rxVZ-KxphRa"},"source":["We can also remove stop words from the list:"]},{"cell_type":"code","metadata":{"id":"Tp5K809wpWt5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678911850143,"user_tz":0,"elapsed":21,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"2cd37d03-f5f9-4863-dd2f-7e649479fda3"},"source":["all_stopwords = sp.Defaults.stop_words\n","all_stopwords.remove('not')\n","\n","text = \"Paul likes to write code in Python, however he is not too fond of C++.\"\n","text_tokens = word_tokenize(text)\n","tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n","\n","print(tokens_without_sw)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["['Paul', 'likes', 'write', 'code', 'Python', ',', 'not', 'fond', '.']\n"]}]},{"cell_type":"markdown","source":["## Exercise\n","\n","We'll be looking at sentiment analysis on the IMDB movie review dataset later. To prepare for this: \n"," - Try doing some frequency analysis on the dataset, to see how frequently stop words occur in reviews\n"," - Remove the stop words from the reviews and check a few reviews to verify this has been done."],"metadata":{"id":"jLck8uo6e5qS"}},{"cell_type":"code","source":["from tensorflow.keras.datasets import imdb\n","(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=30000)"],"metadata":{"id":"bddK3KSlfRf0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678911856688,"user_tz":0,"elapsed":6565,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"16c70f7c-3420-426e-cb39-f876b7500b31"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17464789/17464789 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"markdown","source":["Note that the data is already tokenised and indexed. We can decode a single sample (one review) as follows:"],"metadata":{"id":"wjvMkZn4gD6L"}},{"cell_type":"code","source":["word_index = imdb.get_word_index()\n","reverse_word_index = dict(\n","    [(value, key) for (key, value) in word_index.items()])\n","decoded_review = \" \".join(\n","    [reverse_word_index.get(i - 3, \"?\") for i in train_data[8]]) \n","decoded_review"],"metadata":{"id":"9JJOTcknfn3p","colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"status":"ok","timestamp":1678911856690,"user_tz":0,"elapsed":11,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"outputId":"7cadf345-fbe4-4396-b4b4-d9fbf2b4507a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n","1641221/1641221 [==============================] - 0s 0us/step\n"]},{"output_type":"execute_result","data":{"text/plain":["\"? just got out and cannot believe what a brilliant documentary this is rarely do you walk out of a movie theater in such awe and amazement lately movies have become so over hyped that the thrill of discovering something truly special and unique rarely happens amores perros did this to me when it first came out and this movie is doing to me now i didn't know a thing about this before going into it and what a surprise if you hear the concept you might get the feeling that this is one of those touchy movies about an amazing triumph covered with over the top music and trying to have us fully convinced of what a great story it is telling but then not letting us in ? this is not that movie the people tell the story this does such a good job of capturing every moment of their involvement while we enter their world and feel every second with them there is so much beyond the climb that makes everything they go through so much more tense touching the void was also a great doc about mountain climbing and showing the intensity in an engaging way but this film is much more of a human story i just saw it today but i will go and say that this is one of the best documentaries i have ever seen\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["i=7\n","print(train_labels[i])\n","word_index = imdb.get_word_index()\n","reverse_word_index = dict(\n","    [(value, key) for (key, value) in word_index.items()])\n","decoded_review = \" \".join(\n","    [reverse_word_index.get(i - 3, \"?\") for i in train_data[i]]) \n","decoded_review"],"metadata":{"id":"hJyt-a0Ii5zj","executionInfo":{"status":"ok","timestamp":1678911946419,"user_tz":0,"elapsed":7,"user":{"displayName":"Paul Greaney","userId":"10408734271692537464"}},"colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"df1f63ff-f077-4ada-9d97-80119f740710"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n"]},{"output_type":"execute_result","data":{"text/plain":["\"? the hamiltons tells the story of the four hamilton siblings teenager francis cory ? twins ? joseph ? darlene mackenzie ? the eldest david samuel who is now the surrogate parent in charge the hamilton's move house a lot ? is unsure why is unhappy with the way things are the fact that his brother's sister kidnap ? murder people in the basement doesn't help relax or calm ? nerves either francis ? something just isn't right when he eventually finds out the truth things will never be the same again br br co written co produced directed by mitchell ? phil ? as the butcher brothers who's only other film director's credit so far is the april fool's day 2008 remake enough said this was one of the ? to die ? at the 2006 after dark horrorfest or whatever it's called in keeping with pretty much all the other's i've seen i thought the hamiltons was complete total utter crap i found the character's really poor very unlikable the slow moving story failed to capture my imagination or sustain my interest over it's 85 a half minute too long 86 minute duration the there's the awful twist at the end which had me laughing out loud there's this really big sustained build up to what's inside a cupboard thing in the hamiltons basement it's eventually revealed to be a little boy with a teddy is that really supposed to scare us is that really supposed to shock us is that really something that is supposed to have us talking about it as the end credits roll is a harmless looking young boy the best 'twist' ending that the makers could come up with the boring plot plods along it's never made clear where the hamiltons get all their money from to buy new houses since none of them seem to work except david in a slaughterhouse i doubt that pays much or why they haven't been caught before now the script tries to mix in every day drama with potent horror it just does a terrible job of combining the two to the extent that neither aspect is memorable or effective a really bad film that i am struggling to say anything good about br br despite being written directed by the extreme sounding butcher brothers there's no gore here there's a bit of blood splatter a few scenes of girls chained up in a basement but nothing you couldn't do at home yourself with a bottle of tomato ketchup a camcorder the film is neither scary since it's got a very middle class suburban setting there's zero atmosphere or mood there's a lesbian suggest incestuous kiss but the hamiltons is low on the exploitation scale there's not much here for the horror crowd br br filmed in ? in california this has that modern low budget look about it it's not badly made but rather forgettable the acting by an unknown to me cast is nothing to write home about i can't say i ever felt anything for anyone br br the hamiltons commits the cardinal sin of being both dull boring from which it never recovers add to that an ultra thin story no gore a rubbish ending character's who you don't give a toss about you have a film that did not impress me at all\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28}]}]}
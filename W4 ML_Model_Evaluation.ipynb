{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "ML Model Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8k8YCh9mvwZh"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFOOZBGCvwZF"
      },
      "source": [
        "# Machine learning training, testing and evaluating\n",
        "\n",
        "**Scikit-learn** is an open-source machine learning library for Python that offers a variety of regression, classification and clustering algorithms. You can find a lot of detailed information on it at this link http://scikit-learn.org\n",
        "\n",
        "In this section we'll continue from the previous session whereby I added some extra columns into the data frame to see if it helps us to predict whether a text message is **ham** or **spam**. We also checked for missing values. The code below is a summary of that in the previous lecture. Run all this code to build the dataset with new variables in it.\n",
        "\n",
        "In this lecture we'll perform a fairly simple classification exercise with scikit-learn. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR-rq6OwvwZK"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "Cngdz-CgvwZM",
        "outputId": "2d8fcde1-3710-4ec6-d8cf-ff72a686badf"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "# Read tsv file into a dataframe object\n",
        "# Press tab to check you are in the correct folder location and to browse\n",
        "# to the tsv file\n",
        "# The sep command indicates this files is separated by tabs\n",
        "dataframe = pd.read_csv(io.BytesIO(uploaded['SMSSpamCollection.tsv']), sep=\"\\t\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9905e501-d9b6-4431-a662-147d042576c9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9905e501-d9b6-4431-a662-147d042576c9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving SMSSpamCollection.tsv to SMSSpamCollection (2).tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55xm01dhvwZN"
      },
      "source": [
        "One of the methods we could use to determine whether a text message is **HAM** or **SPAM** is through examination of the length of characters in each line of text.\n",
        "\n",
        "Let's create a loop that uses a list to contain the number of characters within each line. then we'll add the lenght to the end of each row in the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "224RuLwRvwZN"
      },
      "source": [
        "message_length_col = []\n",
        "for index, row in dataframe.iterrows():\n",
        "    length_message_text = len(row.message)\n",
        "    # add the length of each message to list\n",
        "    message_length_col.append(length_message_text)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMRwrlgLvwZO"
      },
      "source": [
        "Next we'll add this list to the dataframe. I'm also inserting this data under the column heading **length**.\n",
        "\n",
        "See this link for further information \n",
        "https://www.geeksforgeeks.org/adding-new-column-to-existing-dataframe-in-pandas/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGGQsGGrvwZP"
      },
      "source": [
        "# now we'll add the contents of this list to a new column\n",
        "# called \"length\" to the end of our dataframe\n",
        "# See https://www.geeksforgeeks.org/adding-new-column-to-existing-dataframe-in-pandas/\n",
        "dataframe['length'] = message_length_col"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvrlalBVvwZP"
      },
      "source": [
        "ham_data = []\n",
        "spam_data = []\n",
        "for index, row in dataframe.iterrows():\n",
        "    # If the label data is recognised to be \"ham\"\n",
        "    if row[\"label\"] == \"ham\":\n",
        "        ham_data.append(row)\n",
        "    else:\n",
        "        spam_data.append(row)\n",
        "\n",
        "# Convert list to a dataframe before performing descriptive statistics on it\n",
        "ham_dataframe = pd.DataFrame(ham_data)\n",
        "spam_dataframe = pd.DataFrame(spam_data)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fal61L47vwZQ"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgjOocScvwZR"
      },
      "source": [
        "# Define variables first\n",
        "punct_length_col = []\n",
        "punct_count = 0\n",
        "\n",
        "for index, textrow in dataframe.iterrows():\n",
        "    doc_object = nlp(textrow.message)\n",
        "    for word in doc_object:\n",
        "        if word.pos_ == 'PUNCT':           \n",
        "            punct_count += 1\n",
        "    # Sentence is checked so add count to list\n",
        "    punct_length_col.append(punct_count)\n",
        "    punct_count =0   "
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBncbhy4vwZS"
      },
      "source": [
        "It is important to ensure that the list we're going to insert into the text dataframe contaisn the same number of rows. Otherwise we'll get an error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpwOudQpvwZS"
      },
      "source": [
        "#Add punct list to dataframe\n",
        "dataframe['punct'] = punct_length_col"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "81qpeQCHvwZT",
        "outputId": "db9da279-c8ce-4902-aa88-3ef8a232e460"
      },
      "source": [
        "# View top of dataframe content\n",
        "dataframe.head()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "      <th>length</th>\n",
              "      <th>punct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>111</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>29</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>155</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>49</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                            message  length  punct\n",
              "0   ham  Go until jurong point, crazy.. Available only ...     111      4\n",
              "1   ham                      Ok lar... Joking wif u oni...      29      2\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      1\n",
              "3   ham  U dun say so early hor... U c already then say...      49      2\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...      61      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LBdghL5vwZU"
      },
      "source": [
        "There could be enough difference between text length in **SPAM** texts versus **HAM** ones to uniquely identify one against the other, but there is not as distinct difference between the number of punctuations in **HAM** messages compared to **SPAM**.\n",
        "\n",
        "We'll now create a ML model using `scikit learn`. In the next lecture we'll use the text content to build a more accurate ML model.\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bO9R_flvwZV"
      },
      "source": [
        "# Machine Learning model creation through scikit-learn\n",
        "\n",
        "Every algorithm is accessed in `scikit-learn` using an **estimator**.\n",
        "\n",
        "The genral syntax to import a model is:\n",
        "\n",
        ">`from sklearn.family import Model`\n",
        "\n",
        "For example, to use the `linear regression` model, we would use:\n",
        "\n",
        ">`from sklearn.linear_model import LinearRegression`.\n",
        "\n",
        "We can set all of the **estimator** parameters when it is instantiated. If we don't, suitable default values will be applied to the ML model. We can press `SHIFT + TAB` in Jupyter notebook to view all of the possible parameters for each model.\n",
        "<br>\n",
        "For example, if we were creating a Linear regression model, and we wanted it to be normalised, we would set the `normalize` parameter to `True`. We can view all of the parameters of a ML model by using the `print(model)` command.\n",
        "\n",
        "Once the model is created, then we need to fit the model with data. As described in an earlier lecture, the data is split into **training** and **testing** data. We'll work through this process in the upcoming code.\n",
        "\n",
        "Once the data is split, then we can fit (or train) or model on the **training** data using the `model.fit()` command. The syntax is :\n",
        "\n",
        ">`model.fit(X_train, y_train)`\n",
        "\n",
        "Note that I'm using specific syntax to do this. Refer to the earlier lecture on supervised learning for further information. \n",
        "\n",
        "Once the model has been fit and trained on the training data, it is then ready for prediction on the test dataset. We predict data from the trained model using this command:\n",
        "\n",
        ">`predict = model.predict(X_test)`\n",
        "\n",
        "We then evaluate the ML model by comparing predicted value to actual test values. With **classification** models, we will examine accuracy, F1 score etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQygGuQWvwZb"
      },
      "source": [
        "# Split the data into training and testing datasets\n",
        "\n",
        "Before we instantiate our ML model, we'll divide the dataset into 2 smaller training and testing datasets.\n",
        "If we want to divide the DataFrame into two smaller sets, we could use\n",
        "> `train, test = train_test_split(dataframe)`\n",
        "\n",
        "We'll also set up our Features (X) and Labels (y). The Label is simple - we're trying to predict the `label` column in our data. For Features we'll use the `length` and `punct` columns. \n",
        "\n",
        "*Please note, **X** is capitalised and **y** is lowercase.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6CzTZpWvwZb"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TASu7X8TvwZc"
      },
      "source": [
        "# X is the feature data\n",
        "# We're creating a list of column names to\n",
        "# use from our dataframe.\n",
        "# We need 2 brackets as there is more than 1 entry\n",
        "X = dataframe[['length', 'punct']]\n",
        "\n",
        "# This is the label data - 1 entry\n",
        "# so only need 1 set of brackets\n",
        "y = dataframe['label']\n",
        "\n",
        "# Use SHIFT + TAB to see full options and to\n",
        "# copy some contents below\n",
        "# test-size represents percentage to use for testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 1)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhG6tPSAvwZc"
      },
      "source": [
        "Lets examine the size of the training and testing datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn9VJp_6vwZd",
        "outputId": "6e96598e-5cea-4c8a-d03d-16cbeecdbd44"
      },
      "source": [
        "# Contains 2 columns\n",
        "print('X train data shape', X_train.shape)\n",
        "print('X test data shape', X_test.shape)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X train data shape (3900, 2)\n",
            "X test data shape (1672, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oURTWmcrvwZd",
        "outputId": "1878fdf4-afa8-426c-bd94-1631a392afad"
      },
      "source": [
        "# 1 column of label data\n",
        "print('y train data shape', y_train.shape)\n",
        "print('y test data shape', y_test.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y train data shape (3900,)\n",
            "y test data shape (1672,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ272bx5vwZe",
        "outputId": "f7a6493a-66a0-43f4-f32f-7887ed5e7b37"
      },
      "source": [
        "# Index position matches with index\n",
        "# position in X_train\n",
        "y_train"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4393     ham\n",
              "216      ham\n",
              "4471     ham\n",
              "3889     ham\n",
              "5030    spam\n",
              "        ... \n",
              "905      ham\n",
              "5192     ham\n",
              "3980     ham\n",
              "235     spam\n",
              "5157     ham\n",
              "Name: label, Length: 3900, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfzhDXnfvwZe",
        "outputId": "2f327655-4372-4454-98cf-74997441e665"
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      length  punct\n",
            "1078      28      1\n",
            "4028      45      3\n",
            "958       26      0\n",
            "4642       7      1\n",
            "4674     107      4\n",
            "...      ...    ...\n",
            "3954     114      6\n",
            "619       59      2\n",
            "1987      24      1\n",
            "2358      52      1\n",
            "3594      22      1\n",
            "\n",
            "[1672 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZCV97xuvwZf",
        "outputId": "7add476d-298e-4dab-ce19-e37a0bdee89d"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1078     ham\n",
              "4028     ham\n",
              "958      ham\n",
              "4642     ham\n",
              "4674     ham\n",
              "        ... \n",
              "3954    spam\n",
              "619      ham\n",
              "1987     ham\n",
              "2358     ham\n",
              "3594     ham\n",
              "Name: label, Length: 1672, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWvpfVzOvwZf"
      },
      "source": [
        "# Training classifiers with our data\n",
        "Now that we have our training and testing datasets created, we can use this data to build classification models. We'll build several models and see how each one differs according to accuracy.\n",
        "\n",
        "There are several classifiers that we can use for our text datasets. Data can more easily be separated linearly with classifiers such as Naive Bayes and linear SVMs, and might lead to better generalisation than is achieved by other classifiers. See https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html?highlight=classifiers for more information on classifiers.\n",
        "\n",
        "See https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/ for more information on various classifiers that are available to us.\n",
        "\n",
        "There are 4 classifiers that we are going to train and test, and then examine for overall accuracy. There's more than just these models, but these are  particularly suited to sentiment analysis and text classification.\n",
        "\n",
        "(a) Linear classifier<br> \n",
        "(b) Naïve Bayes<br> \n",
        "(c) Random Forest<br> \n",
        "(d) Support Vector Classifier<br> \n",
        "\n",
        "**Note** - as with all classifiers, we need to evaluate overall accuracy of the model after it is built. The theory conveyed by some classifiers does not necessarily carry over to real datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9Fu6CH5vwZg"
      },
      "source": [
        "## Train a Logistic Regression classifier (model)\n",
        "\n",
        "One of the simplest multi-class classification tools is [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
        "\n",
        "The following steps are used with all classifiers, not just logistic regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MHelGrjvwZg"
      },
      "source": [
        "### Step 1 - import the model we want to use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo7wyWQYvwZh"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k8YCh9mvwZh"
      },
      "source": [
        "### Step 2 - create an instance of the model we imported\n",
        "\n",
        "Next we create a specific instance of the model we want to construct. Note that I'm using the same model that I imported in Step 1.\n",
        "\n",
        "There are lots of different settings available for the model. To see these settings, press the `SHIFT + TAB` keys **twice** when the cursor is over the line of code. Then scroll down through the settings window. In this example we are going to use the **L-BFGS** algorithmic solver. See this link for further information on the various parameters available for the logistic regression model https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html \n",
        "\n",
        "The default values are usually good. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siIAUhJOvwZi"
      },
      "source": [
        "### Step 3 - build the model and fit data to it\n",
        "\n",
        "We build the model with any specifc options we want to set that are not the dafult values. In this example, I'm using the **L-BFGS** option.\n",
        "\n",
        "Once the model is built, I provide training data to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "483ymU7XvwZj",
        "outputId": "89370f47-a9bd-4fe5-a6cf-91f8d5aa2ed7"
      },
      "source": [
        "lin_reg_model = LogisticRegression(solver='lbfgs')\n",
        "# Note that the \"fit\" option must be run in the same cell as line above\n",
        "lin_reg_model.fit(X_train, y_train)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsc2YNA7vwZj"
      },
      "source": [
        "## Testing model accuracy\n",
        "\n",
        "Now we are going to test the accurcy of the model using the test data.\n",
        "\n",
        "Firstly we import the `sklearn.metrics` module which includes score functions, performance metrics and pairwise metrics and distance computations. See https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics for more information. \n",
        "\n",
        "Now we create a **predictions** set with some test data. The model has not yet seen this data. It contains **length** amd **punctuation** data for each text message that we already have correct answer for in the **y_test** dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDo2oKSYvwZk"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Create a prediction set:\n",
        "# The model has not yet seen contents of X_test\n",
        "# which is a dataset of message length and punctuation\n",
        "# And we know to expect answers in y_test\n",
        "# which is a list of expected label output\n",
        "lin_reg_model_predictions = lin_reg_model.predict(X_test)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZYZTv4KvwZl"
      },
      "source": [
        "Let's look at the contents of the **predictions** set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9fnlTF7vwZl",
        "outputId": "e6077ec9-e667-4b8d-a045-bd011bc1ad28"
      },
      "source": [
        "# This is the predicted output from the model\n",
        "lin_reg_model_predictions"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ham', 'ham', 'ham', ..., 'ham', 'ham', 'ham'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWaRlJqivwZm"
      },
      "source": [
        "The `metrics` model contains a `confusion metrics` option that provides us with options to build a confusion matrix to evaluate model accuracy. \n",
        "\n",
        "See https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix for more information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTCZfUTjvwZn",
        "outputId": "9542b9c4-d07b-4c38-889b-a6281cf4c37e"
      },
      "source": [
        "# Now we compare what the model predicted \n",
        "# with what is expected as output\n",
        "# Print a confusion matrix\n",
        "print(metrics.confusion_matrix(y_test,lin_reg_model_predictions))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1389   53]\n",
            " [ 222    8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDbdTzI4vwZo"
      },
      "source": [
        "The total number of confusions in this model is 275.\n",
        "\n",
        "We can create a dataframe and add labels to make the confusion matrix easier to read and interpret."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "I68QasAYvwZo",
        "outputId": "e7f9ec8a-2e62-4b81-97b6-d2bfb0498184"
      },
      "source": [
        "# You can make the confusion matrix less confusing by adding labels:\n",
        "dataframe_labels = pd.DataFrame(metrics.confusion_matrix(y_test,lin_reg_model_predictions), \n",
        "                  index=['correct ham','correct spam'], \n",
        "                  columns=['predicted ham','predicted spam'])\n",
        "dataframe_labels"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted ham</th>\n",
              "      <th>predicted spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>correct ham</th>\n",
              "      <td>1389</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>correct spam</th>\n",
              "      <td>222</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              predicted ham  predicted spam\n",
              "correct ham            1389              53\n",
              "correct spam            222               8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwW5gkCDvwZp"
      },
      "source": [
        "From the confusion matrix we can see that the model correctly classified 8 spam messages, and incorrectly classified 53 ham messages as spam.\n",
        "\n",
        "The model is better at correctly classifying ham with 1389 correclty classified, and 53 ham messages were incorrectly classified as spam. But the results are terrible.\n",
        "\n",
        "Accuracy = TP + TN / Total\n",
        "= 1389 + 53 / 1672\n",
        "= 1442/1672 = 0.86\n",
        "\n",
        "Let's look at a classification report to show precison, recall and F1-score.\n",
        "\n",
        "Overall the model is good at predicting **ham**, and not so good at **spam**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcXV36buvwZq",
        "outputId": "b35a7be1-5dcd-4e68-c229-573f561d0553"
      },
      "source": [
        "# Print a classification report\n",
        "print(metrics.classification_report(y_test,lin_reg_model_predictions))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.86      0.96      0.91      1442\n",
            "        spam       0.13      0.03      0.05       230\n",
            "\n",
            "    accuracy                           0.84      1672\n",
            "   macro avg       0.50      0.50      0.48      1672\n",
            "weighted avg       0.76      0.84      0.79      1672\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P5VpEwAvwZr"
      },
      "source": [
        "We can also show the overall accuracy of the model with this command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x25-XEkZvwZr",
        "outputId": "4a26e61a-c0a9-4e21-9df4-d00fb9ff9da7"
      },
      "source": [
        "# Print the overall accuracy\n",
        "print(metrics.accuracy_score(y_test,lin_reg_model_predictions))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8355263157894737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQT4dmrvvwZs"
      },
      "source": [
        "This accuracy value indicates that the overall accuray of the model is less than if the model were just to predict **HAM** for all messages in the test dataset (0.86).\n",
        "\n",
        "Let's evaluate other models that are available to us."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4sgPaEyvwZs"
      },
      "source": [
        "## Train a naïve Bayes classifier\n",
        "\n",
        "One of the most common classifiers is naive Bayes model .See http://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes). for more information. It is particularly good for document classification and spam filtering. \n",
        "\n",
        "We will build this model using the same steps we used earlier. We'll import the model from scikit-learn, create an instance of the model, fit (train) the model using our training data, and then predict data using the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a1HH_JNvwZt",
        "outputId": "1b50b578-321b-48eb-d7d6-8f28230bc47f"
      },
      "source": [
        "# First import the model we want to use\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Create an instance of the model - common model for text data and spam filtering\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "# Fit model to training data\n",
        "nb_model.fit(X_train, y_train)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FdvRleHvwZu",
        "outputId": "da7e25ef-ee00-4625-e7c8-769f5f7c7e27"
      },
      "source": [
        "# Predict answers to data from the X_text dataset\n",
        "# containing text length and punctuation count\n",
        "nb_model_predictions = nb_model.predict(X_test)\n",
        "\n",
        "# Show results in a confusion matrix\n",
        "print(metrics.confusion_matrix(y_test,nb_model_predictions))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1442    0]\n",
            " [ 230    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_HGIEyuvwZv"
      },
      "source": [
        "Overall confusion is 230, down from 275 for the logistic regression classifier.\n",
        "\n",
        "Now we can see that this model is no longer any good at predicting spam at all in our text messages.\n",
        "\n",
        "We can look at this in more detail with the `sklearn metrics` report. The warning from scikit-learn shows us that the model cannot predict spam within the text messages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg38RFIOvwZv",
        "outputId": "6f52935b-8b8c-4494-bb4c-a1308949a35a"
      },
      "source": [
        "print(metrics.classification_report(y_test,nb_model_predictions))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.86      1.00      0.93      1442\n",
            "        spam       0.00      0.00      0.00       230\n",
            "\n",
            "    accuracy                           0.86      1672\n",
            "   macro avg       0.43      0.50      0.46      1672\n",
            "weighted avg       0.74      0.86      0.80      1672\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bDfrvmkvwZw"
      },
      "source": [
        "And we can view the overall accuracy of the model. Note how the overall accuracy appears to suggest that the model is quite accurate, but it is no better than one where only ham is provided as test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JQm5iofvwZx",
        "outputId": "1ff7e7d0-821c-4242-f236-2f78e7cb1d0b"
      },
      "source": [
        "print(metrics.accuracy_score(y_test,nb_model_predictions))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8624401913875598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZS9jBjOvwZx"
      },
      "source": [
        "## Random forest model\n",
        "\n",
        "A random forest is a bagging model, and part of the tree model family. A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. \n",
        "\n",
        "See https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html for more information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J_AdoXavwZy"
      },
      "source": [
        "We will build this model using the same steps we used earlier. We'll import the model from scikit-learn, create an instance of the model, fit (train) the model using our training data, and then predict data using the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OmdLaLCvwZz",
        "outputId": "1ff31dd4-9c22-4ec6-aadb-e52c09f2c56c"
      },
      "source": [
        "# First import the model we want to use\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create an instance of the model - common model for text data and spam filtering\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "# Fit model to training data\n",
        "rf_model.fit(X_train, y_train)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0aHLa_uvwZ0",
        "outputId": "5008f944-9730-4b64-9c15-00283da87ccd"
      },
      "source": [
        "# Predict answers to data from the X_text dataset\n",
        "# containing text length and punctuation count\n",
        "rf_model_predictions = rf_model.predict(X_test)\n",
        "\n",
        "# Show results in a confusion matrix\n",
        "print(metrics.confusion_matrix(y_test,rf_model_predictions))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1352   90]\n",
            " [ 105  125]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2JKckvIvwZ1"
      },
      "source": [
        "Overall confusion is 193 (100 + 93), down from 230 for the Naïve Bayes classifier.\n",
        "\n",
        "Now we can see that this model is better than Naïve Bayes classifier at predicting spam in our text messages.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXZKW9GkvwZ1",
        "outputId": "bbb07794-21c3-46be-e42f-15569ed445e7"
      },
      "source": [
        "print(metrics.classification_report(y_test,rf_model_predictions))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.93      0.94      0.93      1442\n",
            "        spam       0.58      0.54      0.56       230\n",
            "\n",
            "    accuracy                           0.88      1672\n",
            "   macro avg       0.75      0.74      0.75      1672\n",
            "weighted avg       0.88      0.88      0.88      1672\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLnxzIFnvwZ2"
      },
      "source": [
        "It appears that this model is very good at predicting HAM text messages, amd better than the other 2 models when it comes to predicting SPAM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS-Wl075vwZ2",
        "outputId": "990c4326-07f2-41d4-a03a-efaa4a3763cb"
      },
      "source": [
        "print(metrics.accuracy_score(y_test,rf_model_predictions))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8833732057416268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPu_JbTAvwZ3"
      },
      "source": [
        "Overall accuracy of the model suggest that it is better than Logistic Regression (0.84) and Naïve Bayes (0.86).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYevIXbGvwZ3"
      },
      "source": [
        "## Train a Support Vector Classifier (SVC)\n",
        "\n",
        "Lets examine whether a SVM will improve the model accuracy.\n",
        "\n",
        "See https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC for further information on scikit-learn SVC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBHacf-rvwZ3"
      },
      "source": [
        "# Import a Support Vector Classification model (SVC)\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B5utBPTvwZ4",
        "outputId": "9eabac4b-a349-4209-e124-7bed16c4d8ea"
      },
      "source": [
        "# Setting gamma to \"auto\", otherwise the SVC model \n",
        "# returns an error\n",
        "svc_model = SVC(gamma=\"auto\")\n",
        "svc_model.fit(X_train, y_train)\n",
        "\n",
        "svc_model_predictions = svc_model.predict(X_test)\n",
        "\n",
        "print(metrics.confusion_matrix(y_test, svc_model_predictions))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1371   71]\n",
            " [ 104  126]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPwawXqqvwZ4"
      },
      "source": [
        "Overall confusion is (104 + 71) = 175. This is better than Naive Bayes model (230), the Random Forest model (193) and the Logistic Regression classifier (275).\n",
        "\n",
        "And we can examine the metrics report for further detail on overall accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtNqhCuHvwZ5",
        "outputId": "126a6549-1239-453e-ac98-d46005f984f2"
      },
      "source": [
        "print(metrics.classification_report(y_test,svc_model_predictions))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.93      0.95      0.94      1442\n",
            "        spam       0.64      0.55      0.59       230\n",
            "\n",
            "    accuracy                           0.90      1672\n",
            "   macro avg       0.78      0.75      0.77      1672\n",
            "weighted avg       0.89      0.90      0.89      1672\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y81Yy-vvvwZ5"
      },
      "source": [
        "It appears that this model is very good at predicting **HAM** text messages, and better than the other 2 models when it comes to predicting **SPAM**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKmduvrnvwZ6",
        "outputId": "ea56b283-5e2c-44ac-f519-72f8d52734a1"
      },
      "source": [
        "print(metrics.accuracy_score(y_test,svc_model_predictions))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8953349282296651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZviTpqTvwZ7"
      },
      "source": [
        "This model is better than the Naive Bayes model (0.86 overall accuracy) and the Logistic Regression classifier (0.83 overall accuracy) and slightly better than the Random Forest model (0.88)."
      ]
    }
  ]
}